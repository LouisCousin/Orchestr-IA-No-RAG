# Orchestr'IA - Configuration par défaut (Phase 1 + Phase 2 + Phase 2.5 + Phase 3)

# Identifiant utilisateur par défaut (mono-utilisateur, prêt multi-utilisateur)
default_user_id: "user_default"

# Fournisseur IA par défaut
default_provider: "openai"
default_model: "gpt-4o"

# Paramètres de génération
generation:
  temperature: 0.7
  max_tokens: 4096
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0
  number_of_passes: 1

# Mode par défaut
mode: "manual"  # "manual" ou "agentic"

# Checkpoints HITL (mode manuel)
checkpoints:
  after_plan_validation: true
  after_corpus_acquisition: false
  after_extraction: false
  after_prompt_generation: false
  after_generation: false
  final_review: true

# Acquisition du corpus
corpus_acquisition:
  connection_timeout: 15
  read_timeout: 60
  slow_mode_connection_timeout: 30
  slow_mode_read_timeout: 120
  throttle_delay: 1.0
  user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

# Taille cible du document
target_pages: null  # null = automatique

# Charte graphique par défaut (Forgescom)
styling:
  primary_color: "#F0C441"
  secondary_color: "#4E4E50"
  font_title: "Calibri"
  font_body: "Calibri"
  font_size_title: 16
  font_size_body: 11
  margin_top_cm: 2.5
  margin_bottom_cm: 2.5
  margin_left_cm: 2.5
  margin_right_cm: 2.5
  logo_path: null

# Chemins
paths:
  projects: "projects"
  output: "output"
  templates: "templates"
  profiles: "profiles"
  config: "config"

# Retry API
api_retry:
  max_retries: 3
  base_delay: 2.0
  max_delay: 60.0

# Estimation de coûts
cost_estimation:
  enabled: true
  warn_threshold_usd: 5.0

# ── Extraction PDF (Phase 2.5) ──
pdf_extraction:
  docling_page_batch_size: 30        # Pages par lot pour Docling
  docling_batch_threshold: 50        # Seuil de pages pour activer le batch
  coverage_threshold: 0.80           # Ratio min de pages couvertes avant rattrapage pymupdf
  disable_page_images: true          # Désactiver la génération d'images de pages
  disable_picture_classification: true  # Désactiver la classification d'images
  disable_ocr: true                  # Désactiver l'OCR (inutile pour les PDF numériques)

# ═══════════════════════════════════════════
# Phase 2.5 — Pipeline RAG complet
# ═══════════════════════════════════════════

rag:
  # ── Chunking sémantique ──
  chunking:
    strategy: "semantic"           # "semantic" | "fixed"
    max_chunk_tokens: 800
    min_chunk_tokens: 100
    overlap_sentences: 2

  # ── Embeddings ──
  embedding_mode: "local"          # "local" | "api"
  embedding_provider: "local"      # "local" | "openai" | "gemini"
  embedding_model: "text-embedding-3-small"  # Modèle API (si provider != "local")
  batch_size: 512                  # Taille des lots pour embeddings API (augmentée vs 32/64)
  local_model: "intfloat/multilingual-e5-large"
  models_cache_dir: "./models"

  # ── Recherche ──
  top_k: 10                        # Blocs après reranking (Phase 2 : 7)
  relevance_threshold: 0.3
  initial_candidates: 20           # Blocs retournés par ChromaDB avant reranking
  cosine_distance: "cosine"

  # ── Reranking ──
  reranking_enabled: true          # true | false
  reranker_model: "cross-encoder/ms-marco-MiniLM-L-12-v2"

  # ── Filtrage ──
  filter_by_language: true         # Filtrer par langue du projet
  filter_by_doc_type: false        # Filtrer par type de document

# Phase 2 — Génération conditionnelle
conditional_generation:
  enabled: true
  sufficient_threshold: 0.5
  insufficient_threshold: 0.3
  min_relevant_blocks: 3

# ── Mode batch ──
batch:
  enabled: true
  poll_interval_seconds: 30
  timeout_seconds: 3600            # 60 minutes
  fallback_to_realtime: true       # Si batch échoue, repasser en temps réel

# ── Anti-hallucination (Phase 2.5) ──
anti_hallucination:
  enabled: true                    # Injecter le bloc dans les prompts
  needs_source_marker: "{{NEEDS_SOURCE: %s}}"
  warn_on_export: true             # Alerter si marqueurs résiduels

# ── Liaison plan-corpus (Phase 2.5) ──
plan_corpus_linking:
  enabled: true                    # Activer la pré-analyse du corpus
  max_intro_chunks_per_doc: 3      # Chunks à extraire par document
  max_documents_for_theme: 30      # Limite pour l'analyse thématique

# ═══════════════════════════════════════════
# Phase 3 — Intelligence du pipeline
# ═══════════════════════════════════════════

# ── Évaluation de la qualité ──
quality_evaluation:
  enabled: true
  auto_refine_threshold: 3.0          # Score global min avant raffinement auto
  weights:                             # Pondérations des critères
    plan_conformity: 1.0
    corpus_coverage: 1.5
    narrative_coherence: 0.8
    target_size: 0.5
    factual_reliability: 1.5
    source_traceability: 1.2
  evaluation_model: null               # null = modèle le plus économique

# ── Vérification factuelle ──
factcheck:
  enabled: true
  auto_correct_threshold: 80           # Score min (%) avant correction auto
  max_claims_per_section: 30           # Limite d'affirmations analysées
  factcheck_model: null                # null = modèle le plus économique

# ── Feedback loop ──
feedback_loop:
  enabled: true
  min_diff_ratio: 0.15                 # Seuil min de différence (Levenshtein)
  analysis_model: null                 # null = modèle de brouillon

# ── Glossaire ──
glossary:
  enabled: false                       # Désactivé par défaut (optionnel)
  max_terms_per_prompt: 15
  auto_generate: true                  # Proposition automatique après plan

# ── Citations APA ──
citations:
  enabled: false                       # Désactivé par défaut
  format: "apa7"                       # Format de référence
  include_page_numbers: true           # Inclure les numéros de page

# ── GROBID ──
grobid:
  enabled: false                       # Désactivé par défaut (Docker requis)
  server_url: "http://localhost:8070"
  timeout_seconds: 30
  consolidate_header: true
  batch_size: 5

# ── Personas ──
personas:
  enabled: false                       # Désactivé par défaut (optionnel)
  auto_suggest: true                   # Suggestion automatique par l'IA

# ── Dashboard ──
dashboard:
  refresh_interval_seconds: 5
  max_log_entries: 100

# ═══════════════════════════════════════════
# Phase 5 — Gemini 3.1 et Context Caching
# ═══════════════════════════════════════════

gemini:
  # ── Context Caching ──
  caching_enabled: false          # Activé si provider = google et modèle 3.1-pro
  cache_ttl_seconds: 7200         # TTL du cache (2h par défaut)

  # ── Thinking Level ──
  thinking_level_mode: "auto"     # "auto" | "manual"
  manual_thinking_level: "medium" # Valeur si mode = "manual"
  thinking_levels:
    summary: "low"
    plan_generation: "medium"
    section_generation: "high"
    refinement: "high"
    quality_evaluation: "medium"
    factcheck: "high"
    feedback_analysis: "low"
    metadata_extraction: "minimal"
  default_thinking_level: "medium"

# ═══════════════════════════════════════════
# Phase 6 — Acquisition GitHub (API REST, No-RAG)
# ═══════════════════════════════════════════

# ═══════════════════════════════════════════
# Phase 7 — Orchestration multi-agents
# ═══════════════════════════════════════════

multi_agent:
  enabled: false                   # Désactivé par défaut, activable en UI

  # Parallélisme
  max_parallel_writers: 4          # Rédacteurs simultanés max
  max_parallel_verifiers: 4        # Vérificateurs simultanés max

  # Seuils
  quality_threshold: 3.5           # Score min (sur 5.0) pour passer à l'export
  section_correction_threshold: 3.0 # Score min par section avant correction
  max_correction_passes: 2         # Passes max de correction par section

  # Budget
  max_cost_usd: 5.0                # Avertissement si estimation > ce seuil

  # Configuration par agent
  agents:
    architecte:
      provider: anthropic
      model: claude-opus-4-6
      temperature: 0.3
      max_tokens: 4096
      timeout_s: 180

    redacteur:
      provider: openai
      model: gpt-4.1
      temperature: 0.7
      max_tokens: 4096
      timeout_s: 120

    verificateur:
      provider: anthropic
      model: claude-opus-4-6
      temperature: 0.2
      max_tokens: 2048
      timeout_s: 120

    evaluateur:
      provider: openai
      model: gpt-4o
      temperature: 0.1
      max_tokens: 1024
      timeout_s: 60

    correcteur:
      provider: openai
      model: gpt-4.1
      temperature: 0.5
      max_tokens: 4096
      timeout_s: 120
      max_tool_calls: 10

github_acquisition:
  enabled: true

  # Limites de sélection
  max_file_size_kb: 500            # Ignorer les fichiers > 500 Ko
  max_total_files: 500             # Limite de fichiers sélectionnables
  max_total_tokens: 500000         # Budget tokens pour le corpus GitHub

  # Assemblage du corpus
  include_repo_structure: true     # Inclure l'arbre textuel du dépôt
  include_repo_metadata: true      # Inclure description, langages, topics
  include_readme_first: true       # Placer le README en tête de corpus

  # Patterns de filtrage (fnmatch)
  include_patterns:
    # Code source
    - '*.py'
    - '*.js'
    - '*.ts'
    - '*.tsx'
    - '*.jsx'
    - '*.java'
    - '*.go'
    - '*.rs'
    - '*.c'
    - '*.cpp'
    - '*.h'
    - '*.rb'
    - '*.php'
    - '*.swift'
    - '*.kt'
    # Documentation
    - '*.md'
    - '*.rst'
    - '*.txt'
    # Configuration
    - '*.yaml'
    - '*.yml'
    - '*.json'
    - '*.toml'
    - 'Dockerfile'
    - 'Makefile'
    - '*.sh'

  exclude_patterns:
    - '.git/**'
    - 'node_modules/**'
    - 'vendor/**'
    - '__pycache__/**'
    - '*.pyc'
    - '*.min.js'
    - '*.min.css'
    - '*.lock'
    - '*.sum'
    - 'dist/**'
    - 'build/**'
    - '.next/**'
    - '*.map'
    - '*.wasm'
    - '*.bin'
    - '*.png'
    - '*.jpg'
    - '*.gif'
    - '*.svg'
    - '*.ico'
    - '*.woff*'
    - '*.ttf'
